# -*- coding: utf-8 -*-
"""Twitter Stock Sentiment Analysis model using NLP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RqPB9Zf9OP9OM2JlKeUGJTcWUu4z_T0X
"""

import requests
import pandas as pd
import re
from datetime import datetime, timedelta
import requests
import pandas as pd
!pip install flair
import flair
# import yfinance as yf
import requests
import matplotlib.pyplot as plt

import requests
!pip install flair
import flair

params = {'q': 'Brightcom',
          'tweet_mode': 'extended',
          'lang':'en',
          'count':100}

bearer_token = 'AAAAAAAAAAAAAAAAAAAAAKc5VgEAAAAAPhWy5OYBSbvE1mnZktlXw16W2qU%3DLONzCAB86pYAsVwHuEaCQYVYZSq4OQvFFEgk3MwwbCZtzmasqa'

response = requests.get('https://api.twitter.com/1.1/search/tweets.json',
    params=params,
    headers={'authorization': 'Bearer '+ bearer_token})

sentiment_model = flair.models.TextClassifier.load('en-sentiment')

with open('bearer_token.txt') as fp:
    bearer_token = fp.read()


def get_data(tweet):
    data = {
        'id': tweet['id'],
        'created_at': tweet['created_at'],
        'text': tweet['text']
    }
    return data

endpoint = 'https://api.twitter.com/2/tweets/search/recent'
headers = {'authorization': f'Bearer {bearer_token}'}
params = {
    'query': '(Brightcom OR brightcom OR bright com) (lang:en)',
    'max_results': '100',
    'tweet.fields': 'created_at,lang'
}

dtformat = '%Y-%m-%dT%H:%M:%SZ'

def time_travel(now, mins):
    now = datetime.strptime(now, dtformat)
    back_in_time = now - timedelta(minutes=mins)
    return back_in_time.strftime(dtformat)

now = datetime.now() - timedelta(seconds=11)
last_week = now - timedelta(days=6)
now = now.strftime(dtformat)

df2 = pd.DataFrame()

df2 = pd.DataFrame()

while True:
    if datetime.strptime(now, dtformat) < last_week:
        break
    pre60 = time_travel(now, 60)
    params['start_time'] = pre60
    params['end_time'] = now
    response = requests.get(endpoint,
                            params=params,
                            headers=headers)
    now = pre60
    for tweet in response.json()['data']:
        row = get_data(tweet)
        df2 = df2.append(row, ignore_index=True)

whitespace = re.compile(r"\s+")
web_address = re.compile(r"(?i)http(s):\/\/[a-z0-9.~_\-\/]+")
name = re.compile(r"(?i)@Brightcom(?=\b)")
user = re.compile(r"(?i)@[a-z0-9_]+")

for i in range(len(df2['text'])):
    df2['text'][i] = whitespace.sub(' ', df2['text'][i])
    df2['text'][i] = web_address.sub('', df2['text'][i])
    df2['text'][i] = name.sub('Brightcom', df2['text'][i])
    df2['text'][i] = user.sub('', df2['text'][i])

print(df2.head())
probs, sentiments = [], []
for tweet in df2['text'].to_list():
    # make prediction
    sentence = flair.data.Sentence(tweet)
    sentiment_model.predict(sentence)
    # extract sentiment prediction
    probs.append(sentence.labels[0].score)  # numerical score 0-1
    sentiments.append(sentence.labels[0].value)  # 'POSITIVE' or 'NEGATIVE'


df2['probability'] = probs
df2['sentiment'] = sentiments

import matplotlib.pyplot as plt
plt.figure(figsize=(20,6))
plt.title('Brightcom', fontsize=20)
plt.pie(df2['sentiment'].value_counts(), explode=[0.05,0], startangle=30, labels=df2['sentiment'].value_counts().index, wedgeprops={'edgecolor':'black', 'linewidth':2}, autopct='%1.1f%%', colors=['#24DE66', '#D82424'])
plt.show()

sentiments = df2['sentiment'].replace({"NEGATIVE":-1, "POSITIVE":1})
final = df2['probability']*sentiments
final.sum()

df2